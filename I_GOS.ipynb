{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bahador1/I-GOS/blob/main/I_GOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AGj7lFFxwO5j"
      },
      "outputs": [],
      "source": [
        "#coding=utf-8\n",
        "# Generating video using I-GOS\n",
        "# python Version: python3.6\n",
        "# by Zhongang Qi (qiz@oregonstate.edu)\n",
        "# from util import *\n",
        "import os\n",
        "import time\n",
        "import scipy.io as scio\n",
        "import datetime\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "import os\n",
        "import csv\n",
        "from skimage import transform, filters\n",
        "from textwrap import wrap\n",
        "import cv2\n",
        "#coding=utf-8\n",
        "# util.py\n",
        "# python Version: python3.6\n",
        "# by Zhongang Qi (qiz@oregonstate.edu)\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "#mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import filters\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
        "Tensor = FloatTensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "progression of img\n",
        "- `Get_blurred_img`:\n",
        "    1.   `cv2.imread(input_img, 1)`, `1` → Loads a color image in BGR format (default)\n",
        "    2.   `cv2.resize(original_img, resize_shape)`\n",
        "    3.   `np.float32(original_img)`\n",
        "    4.   `.../ 255`\n",
        "    5. `preprocess_image(img,...)`\n",
        "        1. -\n",
        "        2. BGR → RGB(common when reading images with OpenCV).\n",
        "        3. normalization with standard ImageNet normalization values.\n",
        "        4. Converts from shape `(H, W, C)` to `(C, H, W)`/ which PyTorch expects.\n",
        "        5. torch.from_numpy (`.cuda()`, `.cpu()`)\n",
        "        6. `unsqueeze(0)`  (1, C, H, W).\n",
        "    6. **output**:\n",
        "        - `original_image`: resized numpy image / BGR\n",
        "        - `img`: - BGR - , np.float32()/ 255\n",
        "        - `blurred_img`: -BGR - np.float32()/255\n",
        "        - `logitori`"
      ],
      "metadata": {
        "id": "9FKBV8Xsa5OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def topmaxPixel(HattMap, thre_num):\n",
        "\n",
        "    ## only keep the top `thre_num` pixels in the mask for deletion\n",
        "    ii = np.unravel_index(np.argsort(HattMap.ravel())[: thre_num], HattMap.shape)\n",
        "    #print(ii)\n",
        "    OutHattMap = HattMap*0\n",
        "    OutHattMap[ii] = 1\n",
        "\n",
        "    img_ratio = np.sum(OutHattMap) / OutHattMap.size\n",
        "    #print(OutHattMap.size)\n",
        "    OutHattMap = 1 - OutHattMap\n",
        "\n",
        "\n",
        "    return OutHattMap, img_ratio\n",
        "\n",
        "\n",
        "def topmaxPixel_insertion(HattMap, thre_num):\n",
        "    ii = np.unravel_index(np.argsort(HattMap.ravel())[: thre_num], HattMap.shape)\n",
        "    # print(ii)\n",
        "    OutHattMap = HattMap * 0\n",
        "    OutHattMap[ii] = 1\n",
        "\n",
        "    img_ratio = np.sum(OutHattMap) / OutHattMap.size\n",
        "\n",
        "    return OutHattMap, img_ratio\n",
        "\n",
        "\n",
        "def tv_norm(input, tv_beta):\n",
        "    img = input[0, 0, :]\n",
        "    row_grad = torch.mean(torch.abs((img[:-1, :] - img[1:, :])).pow(tv_beta))\n",
        "    col_grad = torch.mean(torch.abs((img[:, :-1] - img[:, 1:])).pow(tv_beta))\n",
        "    return row_grad + col_grad\n",
        "\n",
        "\n",
        "def preprocess_image(\n",
        "        img: np.ndarray,\n",
        "        use_cuda: bool = True,\n",
        "        require_grad: bool = False) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "\n",
        "    what does this function do?\n",
        "    These means and stds are the standard ImageNet normalization values.\n",
        "    Most pretrained PyTorch models (like ResNet, VGG) expect input images\n",
        "    normalize with these.\n",
        "\n",
        "    This reverses the channel order. If your input is in RGB,\n",
        "    it becomes BGR (common when reading images with OpenCV).\n",
        "\n",
        "    output:\n",
        "    1. `preprocessed_img_tensor`: normalized\n",
        "    \"\"\"\n",
        "    means = [0.485, 0.456, 0.406]\n",
        "    stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "    preprocessed_img = img.copy()[:, :, ::-1]# (224,224,BGR) -> (224, 224, RGB)\n",
        "\n",
        "    for i in range(3):\n",
        "        # But notice: this assumes img has pixel values already scaled to [0,1],\n",
        "        # otherwise the normalization won’t work as intended.\n",
        "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
        "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
        "    preprocessed_img = \\\n",
        "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
        "        #Ensures the array is contiguous in memory for efficient tensor conversion.\n",
        "\n",
        "    if use_cuda:\n",
        "        preprocessed_img_tensor = torch.from_numpy(preprocessed_img).cuda()\n",
        "    else:\n",
        "        preprocessed_img_tensor = torch.from_numpy(preprocessed_img)\n",
        "\n",
        "    preprocessed_img_tensor.unsqueeze_(0)\n",
        "    return Variable(preprocessed_img_tensor, requires_grad=require_grad)\n",
        "\n",
        "\n",
        "def numpy_to_torch(img, use_cuda=1, requires_grad=False):\n",
        "    if len(img.shape) < 3:\n",
        "        output = np.float32([img])\n",
        "    else:\n",
        "        output = np.transpose(img, (2, 0, 1))\n",
        "\n",
        "    output = torch.from_numpy(output)\n",
        "    if use_cuda:\n",
        "        output = output.cuda()\n",
        "\n",
        "    output.unsqueeze_(0)\n",
        "    v = Variable(output, requires_grad=requires_grad)\n",
        "    return v\n",
        "\n",
        "\n",
        "def load_model_new(use_cuda = 1, model_name = 'resnet50'):\n",
        "\n",
        "    if model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=True)\n",
        "    elif model_name == 'vgg19':\n",
        "        model = models.vgg19(pretrained=True)\n",
        "\n",
        "    #print(model)\n",
        "    model.eval()\n",
        "    if use_cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_heatmap(output_path, upsampled_mask, img, blurred, blur_mask=0):\n",
        "    \"\"\"\n",
        "    input:\n",
        "    save_heatmap(output_file, upsampled_mask, img * 255, blurred_img, blur_mask=0)\n",
        "    \"\"\"\n",
        "\n",
        "    mask  = upsampled_mask\n",
        "    mask = mask.cpu().data.numpy()[0]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    mask = (mask - np.min(mask)) / (np.max(mask)-np.min(mask))\n",
        "    mask = 1 - mask\n",
        "\n",
        "    # if blur_mask:\n",
        "    #     mask = cv2.GaussianBlur(mask, (11, 11), 10)\n",
        "    #     mask = np.expand_dims(mask, axis=2)\n",
        "\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
        "    heatmap = np.float32(heatmap) / 255\n",
        "\n",
        "\n",
        "    img = np.float32(img) / 255\n",
        "    perturbated = np.multiply(1 - mask, img) + np.multiply(mask, blurred)\n",
        "\n",
        "    IGOS = 1 * (1 - mask ** 0.8) * img + (mask ** 0.8)* heatmap;\n",
        "\n",
        "\n",
        "\n",
        "    cv2.imwrite(output_path + \"heatmap.png\", np.uint8(255 * heatmap))\n",
        "    cv2.imwrite(output_path + \"IGOS.png\", np.uint8(255 * IGOS))\n",
        "    cv2.imwrite(output_path + \"blurred.png\", np.uint8(255 * blurred))"
      ],
      "metadata": {
        "id": "jJASlzYHaUEf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_new(mask, img, blurred):\n",
        "    ########################\n",
        "    # generate the perturbed image\n",
        "    #\n",
        "    # parameters:\n",
        "    # mask: the generated mask\n",
        "    # img: the original image\n",
        "    # blurred: the baseline image\n",
        "\n",
        "\n",
        "\n",
        "    #output\n",
        "    # ed, ed ,ed masked image\n",
        "    ####################################################\n",
        "    mask = mask.cpu().data.numpy()[0]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    img = np.float32(img) / 255\n",
        "    perturbated = np.multiply(mask, img) + np.multiply(1-mask, blurred)\n",
        "    perturbated = cv2.cvtColor(perturbated, cv2.COLOR_BGR2RGB)\n",
        "    return perturbated\n"
      ],
      "metadata": {
        "id": "q3Eu6VXam11Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sIEXEm178_3X"
      },
      "outputs": [],
      "source": [
        "def Get_blurred_img(input_img, img_label, model, resize_shape=(224, 224), Gaussian_param = [51, 50], Median_param = 11, blur_type= 'Gaussian', use_cuda = 1):\n",
        "    ########################\n",
        "    # Generate blurred images as the baseline\n",
        "\n",
        "    # Parameters:\n",
        "    # -------------\n",
        "    # input_img: the original input image\n",
        "    # img_label: the classification target that you want to visualize (img_label=-1 means the top 1 classification label)\n",
        "    # model: the model that you want to visualize\n",
        "    # resize_shape: the input size for the given model\n",
        "    # Gaussian_param: parameters for Gaussian blur\n",
        "    # Median_param: parameters for median blur\n",
        "    # blur_type: Gaussian blur or median blur or mixed blur\n",
        "    # use_cuda: use gpu (1) or not (0)\n",
        "\n",
        "    #output\n",
        "    # ----\n",
        "    # original_img: resized numpy image\n",
        "    # img:  - BGR -,   np.float32()/255\n",
        "    # blurred_img -BGR - np.float32()/255\n",
        "    # logitori: class score\n",
        "    ####################################################\n",
        "\n",
        "    original_img = cv2.imread(input_img, 1)#1 → Loads a color image in BGR format (default)\n",
        "    original_img = cv2.resize(original_img, resize_shape)\n",
        "    img = np.float32(original_img) / 255\n",
        "\n",
        "    if blur_type =='Gaussian':   # Gaussian blur\n",
        "        Kernelsize = Gaussian_param[0]\n",
        "        SigmaX = Gaussian_param[1]\n",
        "        blurred_img = cv2.GaussianBlur(img, (Kernelsize, Kernelsize), SigmaX)\n",
        "\n",
        "    elif blur_type == 'Median': # Median blur\n",
        "        Kernelsize_M = Median_param\n",
        "        blurred_img = np.float32(cv2.medianBlur(original_img, Kernelsize_M)) / 255\n",
        "\n",
        "    elif blur_type == 'Mixed': # Mixed blur\n",
        "        Kernelsize = Gaussian_param[0]\n",
        "        SigmaX = Gaussian_param[1]\n",
        "        blurred_img1 = cv2.GaussianBlur(img, (Kernelsize, Kernelsize), SigmaX)\n",
        "\n",
        "        Kernelsize_M = Median_param\n",
        "        blurred_img2 = np.float32(cv2.medianBlur(original_img, Kernelsize_M)) / 255\n",
        "\n",
        "        blurred_img = (blurred_img1 + blurred_img2) / 2\n",
        "\n",
        "\n",
        "\n",
        "    img_torch = preprocess_image(img, use_cuda, require_grad = False)\n",
        "    # blurred_img_torch = preprocess_image(blurred_img, use_cuda, require_grad = False)\n",
        "\n",
        "    ori_output = model(img_torch)\n",
        "    # blurred_output = model(blurred_img_torch)\n",
        "\n",
        "    # compute the outputs for the original image and the blurred image\n",
        "    if use_cuda:\n",
        "        logitori = ori_output.data.cpu().numpy().copy().squeeze()\n",
        "        # logitblur = blurred_output.data.cpu().numpy().copy().squeeze()\n",
        "    else:\n",
        "        logitori = ori_output.data.numpy().copy().squeeze()\n",
        "        # logitblur = blurred_output.data.cpu().numpy().copy().squeeze()\n",
        "\n",
        "\n",
        "    # top_5_idx = np.argsort(logitori)[-5:]\n",
        "    # top_5_values = [logitori[i] for i in top_5_idx]\n",
        "    # print('top_5_idx:', top_5_idx, top_5_values)\n",
        "\n",
        "    # find the original top 1 classification label\n",
        "    # rew = np.where(logitori == np.max(logitori))\n",
        "    #print(rew)\n",
        "    # output_label = rew[0][0]\n",
        "\n",
        "    # if img_label=-1, choose the original top 1 label as the one that you want to visualize\n",
        "    # if img_label == -1:\n",
        "    #     img_label = output_label\n",
        "\n",
        "    # rew_blur = np.where(logitblur == np.max(logitblur))\n",
        "    # output_label_blur = rew_blur[0][0]\n",
        "\n",
        "\n",
        "\n",
        "    #print('ori_output:', ori_output[0, img_label], output_label)\n",
        "    #print('blurred_output:', blurred_output[0, img_label], output_label_blur)\n",
        "    # blur_ratio = blurred_output[0, img_label] / ori_output[0, img_label]\n",
        "    #print('blur_ratio:', blur_ratio)\n",
        "\n",
        "\n",
        "    return original_img, img, blurred_img, logitori\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Integrated_Mask(img, blurred_img, model, category, max_iterations = 15, integ_iter = 20,\n",
        "                    tv_beta=2, l1_coeff = 0.01*300, tv_coeff = 0.2*300, size_init = 112, use_cuda =0):\n",
        "    ########################\n",
        "    # IGOS: using integrated gradient descent to find the smallest and smoothest area that maximally decrease the output of a deep model\n",
        "\n",
        "    # Parameters:\n",
        "    # -------------\n",
        "    # img: the original input image\n",
        "    # blurred_img: the baseline for the input image\n",
        "    # model: the model that you want to visualize\n",
        "    # category: the classification target that you want to visualize (category=-1 means the top 1 classification label)\n",
        "    # max_iterations: the max iterations for the integrated gradient descent\n",
        "    # integ_iter: how many points you want to use when computing the integrated gradients\n",
        "    # tv_beta: which norm you want to use for the total variation term\n",
        "    # l1_coeff: parameter for the L1 norm\n",
        "    # tv_coeff: parameter for the total variation term\n",
        "    # size_init: the resolution of the mask that you want to generate\n",
        "    # use_cuda: use gpu (1) or not (0)\n",
        "\n",
        "\n",
        "    # return:\n",
        "    # --------------\n",
        "    # mask, upsampled_mask, imgratio, curvetop, curve1, curve2, category\n",
        "    ####################################################\n",
        "    img_ori= img.copy() # me\n",
        "    blurred_img_ori = blurred_img.copy()#me\n",
        "\n",
        "    # preprocess the input image and the baseline image\n",
        "    img_torch         = preprocess_image(img,         use_cuda, require_grad=False)###\n",
        "    blurred_img = preprocess_image(blurred_img, use_cuda, require_grad=False)\n",
        "\n",
        "    resize_size = img_torch.data.shape###\n",
        "    resize_wh = (img_torch.data.shape[2], img_torch.data.shape[3])###\n",
        "\n",
        "    # if use_cuda:\n",
        "    #     zero_img = Variable(torch.zeros(resize_size).cuda(), requires_grad=False)\n",
        "    # else:\n",
        "    #     zero_img = Variable(torch.zeros(resize_size), requires_grad=False)\n",
        "\n",
        "    # initialize the mask\n",
        "    mask_init = np.ones((size_init, size_init), dtype=np.float32)\n",
        "    mask      = numpy_to_torch(mask_init, use_cuda, requires_grad=True)\n",
        "\n",
        "    if use_cuda:\n",
        "        upsample = torch.nn.UpsamplingBilinear2d(size=resize_wh).cuda()\n",
        "    else:\n",
        "        upsample = torch.nn.UpsamplingBilinear2d(size=resize_wh)\n",
        "\n",
        "    # You can choose any optimizer\n",
        "    # The optimizer doesn't matter, because we don't need optimizer.step(), we just use it to compute the gradient\n",
        "    optimizer = torch.optim.Adam([mask], lr=0.1)\n",
        "    #optimizer = torch.optim.SGD([mask], lr=0.1)\n",
        "\n",
        "    target = torch.nn.Softmax(dim=1)(model(img_torch))###\n",
        "    if use_cuda:\n",
        "        category_out = np.argmax(target.cpu().data.numpy())\n",
        "    else:\n",
        "        category_out = np.argmax(target.data.numpy())\n",
        "\n",
        "    # if category=-1, choose the original top 1 category as the one that you want to visualize\n",
        "    if category ==-1:\n",
        "        category = category_out\n",
        "\n",
        "    # print(\"Category with highest probability\", category_out)\n",
        "    # print(\"Category want to generate mask\", category)\n",
        "    print(\"Optimizing.. \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    curve1 = np.array([])\n",
        "    curve2 = np.array([])\n",
        "    curvetop = np.array([])\n",
        "\n",
        "\n",
        "    # Integrated gradient descent\n",
        "    alpha = 0.0001\n",
        "    beta = 0.2\n",
        "\n",
        "    #IGOS optimization using IG\n",
        "    for i in range(max_iterations):\n",
        "        upsampled_mask = upsample(mask)\n",
        "        # The single channel mask is used with an RGB image,\n",
        "        # so the mask is duplicated to have 3 channels\n",
        "        upsampled_mask = \\\n",
        "            upsampled_mask.expand(1, 3, upsampled_mask.size(2), \\\n",
        "                                  upsampled_mask.size(3))\n",
        "\n",
        "\n",
        "        # the l1 term and the total variation term\n",
        "        loss1 = l1_coeff * torch.mean(torch.abs(1 - mask)) + \\\n",
        "                tv_coeff * tv_norm(mask, tv_beta)\n",
        "        loss_all = loss1.clone()\n",
        "\n",
        "        # compute the perturbed image\n",
        "        perturbated_input_base = img_torch.mul(upsampled_mask) + \\\n",
        "                                 blurred_img.mul(1 - upsampled_mask)###\n",
        "                                 ### why? perturbated_input_base\n",
        "\n",
        "        #IG\n",
        "        for inte_i in range(integ_iter):\n",
        "\n",
        "\n",
        "            # Use the mask to perturbated the input image.\n",
        "            integ_mask = 0.0 + ((inte_i + 1.0) / integ_iter) * upsampled_mask\n",
        "\n",
        "\n",
        "            perturbated_input_integ = img_torch.mul(integ_mask) + \\\n",
        "                                     blurred_img.mul(1 - integ_mask)\n",
        "\n",
        "            # add noise\n",
        "            noise = np.zeros((resize_wh[0], resize_wh[1], 3), dtype=np.float32)\n",
        "            noise = noise + cv2.randn(noise, 0, 0.2)\n",
        "            noise = numpy_to_torch(noise, use_cuda, requires_grad=False)\n",
        "\n",
        "            perturbated_input = perturbated_input_integ + noise\n",
        "\n",
        "            new_image = perturbated_input\n",
        "            outputs = torch.nn.Softmax(dim=1)(model(new_image))\n",
        "            loss2 = outputs[0, category]\n",
        "\n",
        "            loss_all = loss_all + loss2/20.0\n",
        "\n",
        "\n",
        "        # compute the integrated gradients for the given target,\n",
        "        # and compute the gradient for the l1 term and the total variation term\n",
        "        optimizer.zero_grad()\n",
        "        loss_all.backward()\n",
        "        whole_grad = mask.grad.data.clone()\n",
        "\n",
        "        loss2_ori = torch.nn.Softmax(dim=1)(model(perturbated_input_base))[0, category]\n",
        "\n",
        "        loss_ori = loss1 + loss2_ori\n",
        "        if i==0:\n",
        "            if use_cuda:\n",
        "                curve1 = np.append(curve1, loss1.data.cpu().numpy())\n",
        "                curve2 = np.append(curve2, loss2_ori.data.cpu().numpy())\n",
        "                curvetop = np.append(curvetop, loss2_ori.data.cpu().numpy())\n",
        "\n",
        "            else:\n",
        "                curve1 = np.append(curve1, loss1.data.numpy())\n",
        "                curve2 = np.append(curve2, loss2_ori.data.numpy())\n",
        "                curvetop = np.append(curvetop, loss2_ori.data.numpy())\n",
        "\n",
        "\n",
        "\n",
        "        if use_cuda:\n",
        "            loss_oridata = loss_ori.data.cpu().numpy()\n",
        "        else:\n",
        "            loss_oridata = loss_ori.data.numpy()\n",
        "\n",
        "\n",
        "\n",
        "        # LINE SEARCH with revised Armijo condition\n",
        "        step = 200.0\n",
        "        MaskClone = mask.data.clone()\n",
        "        MaskClone -= step * whole_grad\n",
        "        MaskClone = Variable(MaskClone, requires_grad=False)\n",
        "        MaskClone.data.clamp_(0, 1) # clamp the value of mask in [0,1]\n",
        "\n",
        "\n",
        "        mask_LS = upsample(MaskClone)   # Here the direction is the whole_grad\n",
        "        Img_LS = img_torch.mul(mask_LS) + \\\n",
        "                 blurred_img.mul(1 - mask_LS)\n",
        "        outputsLS = torch.nn.Softmax(dim=1)(model(Img_LS))\n",
        "        loss_LS = l1_coeff * torch.mean(torch.abs(1 - MaskClone)) + \\\n",
        "                  tv_coeff * tv_norm(MaskClone, tv_beta) + outputsLS[0, category]\n",
        "\n",
        "        if use_cuda:\n",
        "            loss_LSdata = loss_LS.data.cpu().numpy()\n",
        "        else:\n",
        "            loss_LSdata = loss_LS.data.numpy()\n",
        "\n",
        "\n",
        "        new_condition = whole_grad ** 2  # Here the direction is the whole_grad\n",
        "        new_condition = new_condition.sum()\n",
        "        new_condition = alpha * step * new_condition\n",
        "\n",
        "        while loss_LSdata > loss_oridata - new_condition.cpu().numpy():\n",
        "            step *= beta\n",
        "\n",
        "            MaskClone = mask.data.clone()\n",
        "            MaskClone -= step * whole_grad\n",
        "            MaskClone = Variable(MaskClone, requires_grad=False)\n",
        "            MaskClone.data.clamp_(0, 1)\n",
        "            mask_LS = upsample(MaskClone)\n",
        "            Img_LS = img_torch.mul(mask_LS) + \\\n",
        "                     blurred_img.mul(1 - mask_LS)\n",
        "            outputsLS = torch.nn.Softmax(dim=1)(model(Img_LS))\n",
        "            loss_LS = l1_coeff * torch.mean(torch.abs(1 - MaskClone)) + \\\n",
        "                      tv_coeff * tv_norm(MaskClone, tv_beta) + outputsLS[0, category]\n",
        "\n",
        "            if use_cuda:\n",
        "                loss_LSdata = loss_LS.data.cpu().numpy()\n",
        "            else:\n",
        "                loss_LSdata = loss_LS.data.numpy()\n",
        "\n",
        "\n",
        "            new_condition = whole_grad ** 2  # Here the direction is the whole_grad\n",
        "            new_condition = new_condition.sum()\n",
        "            new_condition = alpha * step * new_condition\n",
        "\n",
        "            if step<0.00001:\n",
        "                break\n",
        "\n",
        "        mask.data -= step * whole_grad\n",
        "\n",
        "        #######################################################################################################\n",
        "        # what the fuck is the purpose of the following procedure\n",
        "\n",
        "        if use_cuda:\n",
        "            curve1 = np.append(curve1, loss1.data.cpu().numpy())\n",
        "            curve2 = np.append(curve2, loss2_ori.data.cpu().numpy())\n",
        "        else:\n",
        "            curve1 = np.append(curve1, loss1.data.numpy())\n",
        "            curve2 = np.append(curve2, loss2_ori.data.numpy())\n",
        "\n",
        "        mask.data.clamp_(0, 1)\n",
        "        if use_cuda:\n",
        "            maskdata = mask.data.cpu().numpy()\n",
        "        else:\n",
        "            maskdata = mask.data.numpy()\n",
        "\n",
        "        maskdata = np.squeeze(maskdata)\n",
        "        # only keep top 40 pixels of maskdata for deletion\n",
        "        maskdata, imgratio = topmaxPixel(maskdata, 40)\n",
        "        maskdata = np.expand_dims(maskdata, axis=0)\n",
        "        maskdata = np.expand_dims(maskdata, axis=0)\n",
        "\n",
        "        ###############################################\n",
        "        if use_cuda:\n",
        "            Masktop = torch.from_numpy(maskdata).cuda()\n",
        "        else:\n",
        "            Masktop = torch.from_numpy(maskdata)\n",
        "        # Use the mask to perturbated the input image.\n",
        "        Masktop = Variable(Masktop, requires_grad=False)\n",
        "        MasktopLS = upsample(Masktop)\n",
        "        Img_topLS = img_torch.mul(MasktopLS) + \\\n",
        "                    blurred_img.mul(1 - MasktopLS)###\n",
        "\n",
        "\n",
        "\n",
        "        outputstopLS = torch.nn.Softmax(dim=1)(model(Img_topLS))\n",
        "        loss_top1 = l1_coeff * torch.mean(torch.abs(1 - Masktop)) + \\\n",
        "                    tv_coeff * tv_norm(Masktop, tv_beta)\n",
        "        loss_top2 = outputstopLS[0, category]\n",
        "\n",
        "        if use_cuda:\n",
        "            curvetop = np.append(curvetop, loss_top2.data.cpu().numpy())\n",
        "        else:\n",
        "            curvetop = np.append(curvetop, loss_top2.data.numpy())\n",
        "\n",
        "\n",
        "        if max_iterations >3:\n",
        "\n",
        "            if i == int(max_iterations / 2):\n",
        "                if np.abs(curve2[0] - curve2[i]) <= 0.001:\n",
        "                    print('Adjust Parameter l1_coeff at iteration:', int(max_iterations / 2))\n",
        "                    l1_coeff = l1_coeff / 10\n",
        "\n",
        "            elif i == int(max_iterations / 1.25):\n",
        "                if np.abs(curve2[0] - curve2[i]) <= 0.01:\n",
        "                    print('Adjust Parameters l1_coeff again at iteration:', int(max_iterations / 1.25))\n",
        "                    l1_coeff = l1_coeff / 5\n",
        "\n",
        "\n",
        "            #######################################################################################\n",
        "\n",
        "    upsampled_mask = upsample(mask)\n",
        "\n",
        "    if use_cuda:\n",
        "        mask = mask.data.cpu().numpy().copy()\n",
        "    else:\n",
        "        mask = mask.data.numpy().copy()\n",
        "\n",
        "    return mask, upsampled_mask, imgratio, curvetop, curve1, curve2, category"
      ],
      "metadata": {
        "id": "MXQLYM4NmwcH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def Deletion_Insertion(mask, model, output_path, img_ori, blurred_img_ori, logitori, category, pixelnum = 200, use_cuda =1, blur_mask=0, outputfig = 1):\n",
        "#     ########################\n",
        "#     # Compute the deletion and insertion scores\n",
        "#     #\n",
        "#     # parameters:\n",
        "#     # mask: the generated mask - type? np -\n",
        "#     # model: the model that you want to visualize\n",
        "#     # output_path: where to save the results\n",
        "#     # img_ori: the original image\n",
        "#     # blurred_img_ori: the baseline image\n",
        "#     # logitori: the original output for the input image\n",
        "#     # category: the classification target that you want to visualize (category=-1 means the top 1 classification label)\n",
        "#     # pixelnum: how many points you want to compute the deletion and insertion scores\n",
        "#     # use_cuda: use gpu (1) or not (0)\n",
        "#     # blur_mask: blur the mask or not\n",
        "#     # outputfig: save figure or not\n",
        "#     ####################################################\n",
        "#     print(\"your mask type: \", type(mask))\n",
        "#     sizeM = mask.shape[2] * mask.shape[3]\n",
        "#     # sizeM:  784\n",
        "\n",
        "\n",
        "\n",
        "#     # if blur_mask:\n",
        "#     #     mask = (mask - np.min(mask)) / np.max(mask)\n",
        "#     #     mask = 1 - mask\n",
        "#     #     mask = cv2.GaussianBlur(mask, (51, 51), 50)\n",
        "#     #     mask = 1-mask\n",
        "\n",
        "\n",
        "#     blurred_insert = blurred_img_ori.copy()                             #todo\n",
        "#     blurred_insert = preprocess_image(blurred_insert, use_cuda, require_grad=False)\n",
        "\n",
        "#     img = preprocess_image(img_ori, use_cuda, require_grad=False)\n",
        "#     blurred_img = preprocess_image(blurred_img_ori, use_cuda, require_grad=False)\n",
        "#     resize_wh = (img.data.shape[2], img.data.shape[3])\n",
        "#     # resize_wh: 224, 224\n",
        "\n",
        "#     if use_cuda:\n",
        "#         upsample = torch.nn.UpsamplingBilinear2d(size=resize_wh).cuda()\n",
        "#     else:\n",
        "#         upsample = torch.nn.UpsamplingBilinear2d(size=resize_wh)\n",
        "\n",
        "#     target = torch.nn.Softmax(dim=1)(model(img))\n",
        "\n",
        "#     ####\n",
        "#     if use_cuda:\n",
        "#         category_out = np.argmax(target.cpu().data.numpy())\n",
        "#     else:\n",
        "#         category_out = np.argmax(target.data.numpy())\n",
        "\n",
        "#     ####\n",
        "#     if category == -1:\n",
        "#         category = category_out\n",
        "\n",
        "#     # print(\"Category with highest probability (the model decision)\", category_out)\n",
        "#     # print(\"Category want to generate mask\", category)\n",
        "\n",
        "#     #category out: label\n",
        "#     # target: softmax probablity\n",
        "\n",
        "#     outmax = target[0, category].cpu().data.numpy()\n",
        "\n",
        "#     print(\"target.shape\", target.shape)    # target.shape torch.Size([1, 1000])\n",
        "#     # print(\"outmax: Iguess its the class score\", outmax)  yes 0.9959009\n",
        "\n",
        "#     # logitori = logitori[category]\n",
        "\n",
        "#     del_curve = np.array([])\n",
        "#     insert_curve = np.array([])\n",
        "\n",
        "\n",
        "\n",
        "#     # print(\"sizeM: \", sizeM)# 784\n",
        "#     if sizeM<pixelnum:\n",
        "#         #this is the confusing part\n",
        "#         intM = 1\n",
        "#         # Q: is this initialize M  = 1?\n",
        "#     else:\n",
        "#         #where were we? int(sizeM/pixelnum) = int(3.92) = 3.\n",
        "#         intM = int(sizeM/pixelnum)\n",
        "\n",
        "\n",
        "#     xtick = np.arange(0, int(sizeM/3.5), intM)\n",
        "#     print(\"xtick: \", xtick)\n",
        "\n",
        "#     #  xtick:  [  0   3   6   9  12  15  18  21  24  27  30  33  36  39  42  45  48  51\n",
        "#     #     54  57  60  63  66  69  72  75  78  81  84  87  90  93  96  99 102 105\n",
        "#     #     108 111 114 117 120 123 126 129 132 135 138 141 144 147 150 153 156 159\n",
        "#     #     162 165 168 171 174 177 180 183 186 189 192 195 198 201 204 207 210 213\n",
        "#     #     216 219 222]\n",
        "\n",
        "#     xnum = xtick.shape[0]\n",
        "#     print('xnum:', xnum) #xnum = 75\n",
        "\n",
        "#     xtick = xtick.shape[0]+ 10\n",
        "\n",
        "#     # get the name(e.g. fox squirrel) of the ground truth label for the given category, and from the GroundTruth1000.txt\n",
        "#     f_groundtruth = open('./GroundTruth1000.txt')\n",
        "#     line_i = f_groundtruth.readlines()[category]\n",
        "#     f_groundtruth.close()\n",
        "#     # print('line_i:', line_i)\n",
        "\n",
        "\n",
        "#     # the hell we are doing here ?\n",
        "#     ## deletion\n",
        "#     ## insertion\n",
        "#     for pix_num in range(0, int(sizeM/3.5), intM):\n",
        "#         #pix_num : xtick steps\n",
        "\n",
        "#         ###############################deletion####################################\n",
        "#         maskdata = mask.copy()\n",
        "#         #mask generated by the Integrated_Mask(...)\n",
        "#         #isnt this the dumbestthing that one can do in the world?\n",
        "#         print(\"maskdata.shape\", maskdata.shape)\n",
        "#         maskdata = np.squeeze(maskdata)\n",
        "\n",
        "#         # only keep the top pixels in the mask for deletion\n",
        "#         maskdata, imgratio = topmaxPixel(maskdata, pix_num)\n",
        "#         maskdata = np.expand_dims(maskdata, axis=0)\n",
        "#         maskdata = np.expand_dims(maskdata, axis=0)\n",
        "\n",
        "#         ###############################################\n",
        "#         if use_cuda:\n",
        "#             Masktop = torch.from_numpy(maskdata).cuda()\n",
        "#         else:\n",
        "#             # Masktop = torch.from_numpy(maskdata)\n",
        "#             Masktop = torch.from_numpy(maskdata).float()\n",
        "\n",
        "#         # Use the mask to perturbated the input image.\n",
        "#         # Masktop = Variable(Masktop, requires_grad=False)\n",
        "#         print(\"Masktop.shape \", Masktop.shape)\n",
        "\n",
        "#         MasktopLS = upsample(Masktop)\n",
        "#         print(\"upsample(Masktop)\", MasktopLS.shape)\n",
        "#         Img_topLS = img.mul(MasktopLS) + \\\n",
        "#                     blurred_img.mul(1 - MasktopLS)\n",
        "\n",
        "#         outputstopLS_ori = model(Img_topLS)[0, category].data.cpu().numpy().copy()\n",
        "#         outputstopLS = torch.nn.Softmax(dim=1)(model(Img_topLS))\n",
        "#         delloss_top2 = outputstopLS[0, category].data.cpu().numpy().copy()\n",
        "#         del_mask = MasktopLS.clone()\n",
        "\n",
        "#         delimg_ratio = imgratio.copy()\n",
        "#         del_ratio = delloss_top2 / outmax\n",
        "#         del_curve = np.append(del_curve, delloss_top2)\n",
        "\n",
        "#         ###############################insertion###############################\n",
        "#         ### same thing as the deletion procedure\n",
        "#         maskdata = mask.copy()\n",
        "\n",
        "#         maskdata = np.squeeze(maskdata)\n",
        "\n",
        "#         maskdata, imgratio = topmaxPixel_insertion(maskdata, pix_num)\n",
        "\n",
        "#         maskdata = np.expand_dims(maskdata, axis=0)\n",
        "#         maskdata = np.expand_dims(maskdata, axis=0)\n",
        "\n",
        "#         ###############################################\n",
        "#         if use_cuda:\n",
        "#             Masktop = torch.from_numpy(maskdata).cuda()\n",
        "#         else:\n",
        "#             # Masktop = torch.from_numpy(maskdata)\n",
        "#             Masktop = torch.from_numpy(maskdata).float()\n",
        "\n",
        "#         # Use the mask to perturbated the input image.\n",
        "#         # Masktop = Variable(Masktop, requires_grad=False)\n",
        "#         MasktopLS = upsample(Masktop)\n",
        "#         Img_topLS = img.mul(MasktopLS) + \\\n",
        "#                     blurred_insert.mul(1 - MasktopLS)\n",
        "\n",
        "#         outputstopLS_ori = model(Img_topLS)[0, category].data.cpu().numpy().copy()\n",
        "#         outputstopLS = torch.nn.Softmax(dim=1)(model(Img_topLS))\n",
        "#         insloss_top2 = outputstopLS[0, category].data.cpu().numpy().copy()\n",
        "#         ins_mask = MasktopLS.clone()\n",
        "\n",
        "\n",
        "#         insimg_ratio = imgratio.copy()\n",
        "#         ins_ratio = insloss_top2 / outmax\n",
        "#         insert_curve = np.append(insert_curve, insloss_top2)\n",
        "\n",
        "\n",
        "#         # do you write images ?\n",
        "#         if outputfig == 1:\n",
        "#             deletion_img = save_new(del_mask, img_ori * 255, blurred_img_ori)\n",
        "#             insertion_img = save_new(ins_mask, img_ori * 255, blurred_img_ori)\n",
        "#             #why the hell you multiply img_ori with 255?\n",
        "#             # same img_ori that you passed to this function\n",
        "\n",
        "\n",
        "#             showimage(deletion_img, insertion_img, del_curve, insert_curve, output_path, xtick, line_i)\n",
        "\n",
        "\n",
        "#     outmax = np.around(outmax, decimals=3)\n",
        "#     delloss_top2 = np.around(delloss_top2, decimals=3)\n",
        "#     del_ratio = np.around(del_ratio, decimals=3)\n",
        "#     delimg_ratio = np.around(delimg_ratio, decimals=3)\n",
        "\n",
        "#     insloss_top2 = np.around(insloss_top2, decimals=3)\n",
        "#     ins_ratio = np.around(ins_ratio, decimals=3)\n",
        "#     insimg_ratio = np.around(insimg_ratio, decimals=3)\n",
        "\n",
        "\n",
        "#     return del_mask, ins_mask, delloss_top2, insloss_top2, del_ratio, ins_ratio, outmax, category, xnum\n"
      ],
      "metadata": {
        "id": "1WhBFF4GfOEM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # def write_video(inputpath, outputname, img_num, fps = 10):\n",
        "#     ########################\n",
        "#     # Generate videos\n",
        "#     #\n",
        "#     # parameters:\n",
        "#     # inputpath: the path for input images\n",
        "#     # outputname: the output name for the video\n",
        "#     # img_num: the number of the input images\n",
        "#     # fps: frames per second\n",
        "#     ####################################################\n",
        "\n",
        "\n",
        "#     fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "#     videoWriter = cv2.VideoWriter(outputname, fourcc, fps, (1000, 1000))\n",
        "#     for i in range(img_num):\n",
        "\n",
        "#         img_no = i+1\n",
        "#         # print(inputpath+'video'+str(img_no) +'.jpg')\n",
        "#         img12 = cv2.imread(inputpath+'video'+str(img_no) +'.jpg',1)\n",
        "#         videoWriter.write(img12)\n",
        "#     videoWriter.release()"
      ],
      "metadata": {
        "id": "PkCjb3mkogLa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs5qhjL3TDpG",
        "outputId": "2ba51e07-ca3b-4b6e-f586-b716db830887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_cuda False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_path = './Images/'\n",
        "if not os.path.exists(input_path):\n",
        "    os.makedirs(input_path)\n",
        "\n",
        "\n",
        "output_path = './Results/VIDEO/'\n",
        "if not os.path.isdir(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "files = os.listdir(input_path)\n",
        "# print(files)\n",
        "print(\"use_cuda\", use_cuda)\n",
        "model = load_model_new(use_cuda=use_cuda, model_name='vgg19')  #\n",
        "# for imgname in files:\n",
        "\n",
        "# if imgname.endswith('jpg'):\n",
        "# if imgname.endswith('JPEG'):\n",
        "\n",
        "imgname  = \"ILSVRC2012_val_00001003.JPEG\"\n",
        "input_img = input_path + imgname\n",
        "# print('imgname:', imgname)\n",
        "img_label = -1\n",
        "\n",
        "resized_original_image, img, blurred_img, logitori = Get_blurred_img(input_img, img_label, model, resize_shape=(224, 224),\n",
        "                                                Gaussian_param=[51, 50],\n",
        "                                                Median_param=11, blur_type='Gaussian', use_cuda=use_cuda)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mask, upsampled_mask, imgratio, curvetop, curve1, curve2, category = Integrated_Mask(img, blurred_img, model,\n",
        "                                                                                            img_label,\n",
        "                                                                                            max_iterations=1,\n",
        "                                                                                            integ_iter=1,\n",
        "                                                                                            tv_beta=2,\n",
        "                                                                                            l1_coeff=0.01 * 100,\n",
        "                                                                                            tv_coeff=0.2 * 100,\n",
        "                                                                                            size_init=28,\n",
        "                                                                                            use_cuda=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# mask,                       (1, 1, 28, 28)\n",
        "# upsampled_mask,  torch.Size([1, 1, 224, 224])\n",
        "\n",
        "\n",
        "\n",
        "# outvideo_path = output_path + imgname[:-5] + '/'\n",
        "# if not os.path.isdir(outvideo_path):\n",
        "#     os.makedirs(outvideo_path)\n",
        "\n",
        "# output_file = output_path + imgname[:-4] + '_IGOS_'\n",
        "# save_heatmap(output_file, upsampled_mask, img * 255, blurred_img, blur_mask=0)\n",
        "\n",
        "#scio.savemat(outvideo_path + imgname[:-5] + 'Mask' + '.mat',\n",
        "#             mdict={'mask': mask},\n",
        "#             oned_as='column')\n",
        "\n",
        "# print(\"mask: \", mask.shape)\n",
        "#\n",
        "# output_file = outvideo_path + imgname[:-5] + '_IGOS_'\n",
        "# del_img, ins_img, delloss_top2, insloss_top2, del_ratio, ins_ratio, outmax, cateout, xnum = Deletion_Insertion(mask,\n",
        "                                                                                                                # model,\n",
        "                                                                                                                # output_file,\n",
        "                                                                                                                # img,\n",
        "                                                                                                                # blurred_img,\n",
        "                                                                                                                # logitori,\n",
        "                                                                                                                # category=-1,\n",
        "                                                                                                                # pixelnum=200,\n",
        "                                                                                                                # use_cuda=0,\n",
        "                                                                                                                # blur_mask=0,\n",
        "                                                                                                                # outputfig=0)\n",
        "\n",
        "# print(\"del_img\", del_img.shape)\n",
        "# print(\"ins_img\", ins_img.shape)\n",
        "# print()\n",
        "\n",
        "\n",
        "# #who write this images ?\n",
        "# # it must be deletion_insertion\n",
        "# video_name = outvideo_path + 'AllVideo_fps10' + imgname[:-5] + '.avi'\n",
        "# write_video(output_file, video_name, xnum, fps=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P3gEHw1Lrrb",
        "outputId": "98bcb53e-9ecc-4b44-a209-c2008648f85a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing.. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_oA2XnAU8T2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1NKSnzY6YVkByv04OOm/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}